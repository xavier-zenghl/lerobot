#!/bin/bash

BASE_DIR="/home/xavierzeng/workspace/data/"
ROOT_PATH="/home/xavierzeng/workspace/data/test/"
SCRIPT_DIR="/home/xavierzeng/workspace/code/lerobot/lerobot/data_convert_scripts"
BATCH=1
N_SPLIT=$((BATCH * 1))
GPU_LIST=(0)
GPU_NUM=${#GPU_LIST[@]}

SUBDIR_LIST=(
  "0731_desktop_Storage_S8"
)
REPO_ID_LIST=(
  "lerobot_so3_data_30hz"
)
TASK_DESCRIPTION_LIST=(
  "A robot is positioned in front of the checkout counter, where three different types of items and a shopping bag are placed. Packing in the supermarket."
)

cd "$SCRIPT_DIR" || { echo "âŒ Failed to cd into $SCRIPT_DIR"; exit 1; }

for idx in "${!SUBDIR_LIST[@]}"; do
  RAW_PATH="${BASE_DIR}${SUBDIR_LIST[$idx]}"
  REPO_ID="${REPO_ID_LIST[$idx]}"
  HDF5_DIR="${RAW_PATH}/hdf5"
  MERGED_BASE="${ROOT_PATH}${REPO_ID}"
  MERGED_SPLITS="${MERGED_BASE}/merged1"
  mkdir -p "$MERGED_SPLITS"

  echo "========== å¤„ç† $REPO_ID =========="
  
    # TODO----------------- æ–°å¢æ­¥éª¤0: æ£€æµ‹ç›®æ ‡hdf5æ˜¯å¦åŒ…å«prompté”®å€¼ ------------------
  # echo "ğŸ”µ [Step0] æ£€æµ‹ $HDF5_DIR ä¸‹çš„ HDF5 æ–‡ä»¶æ˜¯å¦åŒ…å« prompt é”®å€¼"
  # python check_hdf5.py "$HDF5_DIR"
  # if [[ $? -ne 0 ]]; then
  #     echo "âŒ check_hdf5.py æ£€æµ‹å¤±è´¥ï¼Œé€€å‡º"; exit 1
  # fi

  # ------------------ æ­¥éª¤1: è‡ªåŠ¨åˆ‡åˆ† ------------------
  echo "ğŸŸ  [Step1] è‡ªåŠ¨åˆ‡åˆ† $HDF5_DIR ä¸º $N_SPLIT ä»½"
  python split_data_folder.py "$HDF5_DIR" $N_SPLIT
  if [[ $? -ne 0 ]]; then
      echo "âŒ split_data_folder.py å¤±è´¥ï¼Œé€€å‡º"; exit 1
  fi

  # ------------------ æ­¥éª¤2: åŠ¨æ€å¹¶å‘ç”Ÿæˆå­æ•°æ®é›† ------------------
  MERGE_INPUTS=()
  running=0
  for ((j=1; j<=N_SPLIT; j++)); do
      SPLIT_PATH="${HDF5_DIR}/split_${j}"
      REPO_SUBID="${REPO_ID}_split_${j}"
      OUT_ROOT="${MERGED_SPLITS}" 
  done
  
      GPU_IDX=$(( (j-1) % GPU_NUM ))
  
      CUDA_VISIBLE_DEVICES=${GPU_LIST[$GPU_IDX]} \
        python convert_hdf5_to_lerobot.py \
          --description "${TASK_DESCRIPTION_LIST[$idx]}" \
          --raw-path "$SPLIT_PATH" \
          --root-path "$OUT_ROOT" \
          --dataset-repo-id "$REPO_SUBID" \
          --hdf5_compressed True \
          --split False &
      running=$((running+1))
      MERGE_INPUTS+=("$OUT_ROOT")
  
      if [[ $running -ge $BATCH ]]; then
          # ç­‰ä»»æ„ä¸€ä¸ªå­ä»»åŠ¡ç»“æŸï¼Œç©ºå‡ºä¸€ä¸ªå¹¶å‘ä½
          wait -n
          running=$((running-1))
      fi
  done
  
  # ç­‰æ‰€æœ‰å‰©ä½™è¿›ç¨‹ç»“æŸ
  wait
  
  echo "âœ… æ‰€æœ‰ split å¤„ç†å®Œæˆ"

  # ------------------ æ­¥éª¤3: åˆå¹¶æ‰€æœ‰ split ------------------
  # è‡ªåŠ¨æŸ¥æ‰¾ merged1 ä¸‹æ‰€æœ‰ split å­æ•°æ®é›†ç›®å½•ï¼ˆ**ä»…è¿™ä¸€æ®µåœ¨è¿è¡Œ**ï¼‰
  MERGE_INPUTS=$(find "$MERGED_SPLITS" -mindepth 1 -maxdepth 1 -type d | paste -sd "," -)
  echo "MERGE_INPUTS: $MERGE_INPUTS"

  echo "ğŸŸ£ [Step3] åˆå¹¶ $REPO_ID çš„æ‰€æœ‰å­æ•°æ®é›†"
  # TODO: åˆå¹¶ç²—ç»†æŒ‡ä»¤
  python merge_split_datasets.py \
      --dataset-dirs "$MERGE_INPUTS" \
      --output-dir "$MERGED_BASE" \
      --chunk-size 1000
  echo "âœ… åˆå¹¶å®Œæˆï¼Œç»“æœåœ¨ï¼š$MERGED_BASE"

  # ------------------ æ­¥éª¤4: æ¸…ç† split ç›®å½• ------------------
  echo "ğŸ—‘ï¸ åˆ é™¤æ‰€æœ‰ split_x ä¸´æ—¶ç›®å½•" 
  for ((j=1; j<=N_SPLIT; j++)); do
      rm -rf "${HDF5_DIR}/split_${j}"
  done

  # ------------------ æ­¥éª¤5ï¼šåˆ é™¤ merged1 ç›®å½•ï¼ˆå…ˆæ³¨é‡Šï¼‰ ------------------
  echo "ğŸ—‘ï¸ åˆ é™¤ ${MERGED_SPLITS} ç›®å½•ï¼ˆåŒ…å«æ‰€æœ‰ split å­é›†ï¼‰"
  rm -rf "${MERGED_SPLITS}"

  echo "============================"
done

echo "ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤¹å…¨éƒ¨å¤„ç†å®Œæˆï¼"

